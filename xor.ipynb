{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import *\n",
    "import random\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "def show_results(D):\n",
    "    # D is a dictionary with classical bits as keys and count as value\n",
    "    # example: D = {'000': 497, '001': 527}\n",
    "    plt.bar(range(len(D)), list(D.values()), align='center')\n",
    "    plt.xticks(range(len(D)), list(D.keys()))\n",
    "    plt.show()\n",
    "\n",
    "# Execute circuit, display a histogram of the results\n",
    "def execute_locally(qc, draw_circuit=False):\n",
    "    # Compile and run the Quantum circuit on a simulator backend\n",
    "    backend_sim = Aer.get_backend('qasm_simulator')\n",
    "    job_sim = execute(qc, backend_sim, shots=1000)\n",
    "    result_sim = job_sim.result()\n",
    "    result_counts = result_sim.get_counts(qc)\n",
    "    # Print the results\n",
    "    print(\"simulation: \\n\\n\", result_counts)\n",
    "    show_results(result_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QFTransform(circuit,qr,swap=False):\n",
    "    i=qr.size\n",
    "    k=1\n",
    "    \n",
    "    for j in reversed(range(i)):\n",
    "        circuit.h(qr[j])\n",
    "\n",
    "        for l in reversed(range(j)):\n",
    "            rot = pi / 2 ** k\n",
    "            circuit.cu1(rot,qr[l],qr[j])\n",
    "            k+=1\n",
    "        k=1\n",
    "        circuit.barrier()\n",
    "    \n",
    "    if swap and qr.size > 1:\n",
    "        i=0\n",
    "        j=qr.size-1\n",
    "        while(i<j):\n",
    "            circuit.swap(qr[i],qr[j])\n",
    "            i+=1\n",
    "            j-=1\n",
    "\n",
    "def iQFTransform(circuit,qr,swap=False):\n",
    "    for i in range(qr.size):\n",
    "        k=i\n",
    "        for l in range(i):\n",
    "            rot = -(pi / 2 ** k)\n",
    "            circuit.cu1(rot,qr[l],qr[i])\n",
    "            k-=1\n",
    "        circuit.h(qr[i])\n",
    "        \n",
    "        circuit.barrier()\n",
    "    \n",
    "    if swap and qr.size > 1:\n",
    "        i=0\n",
    "        j=qr.size-1\n",
    "        while(i<j):\n",
    "            circuit.swap(qr[i],qr[j])\n",
    "            i+=1\n",
    "            j-=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we have a weight vector -> W = {w1,w2,...,w6} and input vector X={x1,x2}\n",
    " The output of each hidden layer will serve as input of the output layer.\n",
    " For each layer we need feedforward operation to calculate $\\sum_{n=1}^{2} W_{n}^{T} X_{n}$. After the summation we will consider a step function to make the activation function.\n",
    " FeedForward can be done in a quantum fashion by writing $\\sum_{n=1}^{2} W_{n}^{T} X_{n}$ in the phase of a quantum register and then using quantum phase estimation to retrieve the approximate value of the summation into the auxiliary register -> $iQFT_{x}(U^{iW}( \\ket x \\otimes \\ket 0))$ -> $\\ket x \\otimes \\ket{W^{T} x}$\n",
    " <br>Next , in order to feed the output of the perceptron as an input to another perceptron we need to perform an activation on the auxiliary register. I'll use the step function because is simply measuring the first qubit of the auxiliary register and thats what we need for this case.<br>\n",
    " After the feedforward we have the output $\\overline y$. We need to obtain the output for each training data in order to compute de loss function $MSE = \\sum_{n=1}^{4}(\\overline y - y)^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=6\n",
    "inputReg = QuantumRegister(2)\n",
    "outputReg = QuantumRegister(1)\n",
    "weightReg = QuantumRegister(w)\n",
    "randWeight = [random.randint(0,1) for x in range(6)]\n",
    "\n",
    "qc = QuantumCircuit(inputReg,outputReg,weightReg)\n",
    "\n",
    "def xorStatePreparation(qc,inputReg,weightReg,randWeight,outputReg):\n",
    "    qc.h(inputReg)\n",
    "    qc.x(inputReg[0])\n",
    "    qc.ccx(inputReg[0],inputReg[1],outputReg[0])\n",
    "    qc.x(inputReg[0])\n",
    "    qc.x(inputReg[1])\n",
    "    qc.ccx(inputReg[0],inputReg[1],outputReg[0])\n",
    "    qc.x(inputReg[1])\n",
    "    for i in range(w):\n",
    "        if randWeight[i] == 1:\n",
    "            qc.x(weightReg[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create a class perceptron for easy and general use.\n",
    " easy to construct the xor neural network\n",
    " perceptron suggested by Maria Schuld et.al using the principle of quantum phase estimation (QPE)\n",
    " We begin with three concrete registers $\\ket{x} \\otimes \\ket w \\otimes \\ket 0$\n",
    " Then we have an oracle that encodes $\\sum_{n=1}^{2} W_{n}^{T} X_{n}$ into the phase of input register\n",
    " QPE is then able to retrieve the weighted sum approximately (greater than 90%) into the ancilla register\n",
    " One way of obtaining the output of the neuron is doing a step activation function on the ancilla register\n",
    " wich is just a measure on the most significant qubit of the ancilla register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qPerceptron:\n",
    "    def __init__(self,qc,inputReg,weightReg):\n",
    "        self.qc = qc\n",
    "        self.inputReg = inputReg\n",
    "        self.weightReg = weightReg\n",
    "        self.ancillaReg = QuantumRegister(len(self.inputReg))\n",
    "        self.qc.add_register(self.ancillaReg)\n",
    "\n",
    "    def feedForward(self):\n",
    "        return self.qPhaseEstimation()\n",
    "    \n",
    "    def qPhaseEstimation(self):\n",
    "        self.qc.h(self.ancillaReg)\n",
    "        self.qOracle(self.qc,self.inputReg,self.weightReg,self.ancillaReg)\n",
    "        iQFTransform(qc,self.ancillaReg,swap=False)\n",
    "        return self.ancillaReg[1]\n",
    "\n",
    "    def qOracle(self,qc,inputReg,weightReg,ancillaReg):\n",
    "        for i in range(ancillaReg.size):\n",
    "            for j in reversed(range(i+1)):\n",
    "                for k in reversed(range(len(weightReg))):\n",
    "                    qc.h(inputReg[k])\n",
    "                    qc.ccx(ancillaReg[i],weightReg[k],inputReg[k])\n",
    "                    qc.h(inputReg[k])\n",
    "    \n",
    "    def setInputReg(self,inputReg):\n",
    "        self.inputReg = inputReg\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " xor-nn will be composed of an hidden layer with two perceptrons that constitutes the input layer. it will have an output layer with 1 perceptron\n",
    " feefforward operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep1 = qPerceptron(qc,inputReg,[weightReg[0],weightReg[1]])\n",
    "out1 = percep1.feedForward()\n",
    "percep2 = qPerceptron(qc,inputReg,[weightReg[2],weightReg[3]])\n",
    "out2 = percep2.feedForward()\n",
    "percep3 = qPerceptron(qc,[out1,out2],[weightReg[4],weightReg[5]])\n",
    "out3 = percep3.feedForward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After the feedforward operation we want to know how bad/good are our predictions compared to the real value. This is done by computing\n",
    " the mean squared error function (MSE) as said above. Now, given that our input training data are given in superposition to the perceptrons,\n",
    " we are training in parallel and so , we only need to do MSE between out3 register and the output register in qc, and in parallel we will be\n",
    " computing the MSE for every training data points.\n",
    " For computing the $MSE = \\sum_{n=1}^{4}(\\overline y - y)^{2}$ we will need to do some quantum arithmetic to obtain the result in a quantum register\n",
    " and then backpropagate the error to the weight parameters\n",
    " Given that we need to do a subtraction and the registers will be of just one qubit , then we only need to perform xor operations with use of an\n",
    " extra ancilla qubit to store the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that the xor-nn is constructed, lets construct a class called deepNN that will be responsible for training and testing the network after the\n",
    " training session. We need to specify the # of epochs that we want to train the nertwork."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The purpose of Quantum BackPropagation procedure (QFB) is the same as in the classical analogue. We want to perform backpropagation of the gradient of the Loss Function -> gradient descent, because in this way we are walking towards the minimum of the loss function , so , we are walking towards the minimum error between our predictions and the real outputs. <br> QFB is based on the principal of the phase kickback. We gonna exponentiate the value of the loss function $L(\\theta)$ into the parameters -> $e^{-i\\eta L(\\theta)}$ , with $\\eta$ being the learning rate. Then, performing the Fourier Transform on these we shift the registers into the momentum space. Performing $e^{-i \\gamma \\theta ^{2}}$ on the parameters, we shift the momentum of these accordingly with the gradient of the loss function. -> $\\theta = \\theta - \\eta \\nabla(L(\\theta))$ <br>\n",
    " We have 2 methods of making QFB: <br>\n",
    " <li>Performing one round of feedforward + backprop is called an epoch. Reverting the effect of the Fourier Transform in the parameters and procede to another epoch -> <b> Quantum Dynamical Descent (QDD) </b></li>\n",
    " <li> Measuring the parameters , performing an unitary to initiate the new parameters and only then procede to another epoch -> <b> Momentum Measurement Gradient Descent (MoMGrad) </b>\n",
    " Tipically $\\eta$ in classical machine Learning is used to be $\\eta$ = 0.1<br>\n",
    " Starting with large kinetic rate $\\gamma >> \\eta$ and with the increasinng of the #epochs change to $\\gamma << \\eta$ helps us to achieve the minimum of the function.\n",
    " Given that we are trying to work strictly with quantum data we will be using QDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class deepNN:\n",
    "    def __init__(self,qc,weightReg,perceptrons):\n",
    "        self.qc = qc\n",
    "        self.perceptrons = perceptrons\n",
    "        self.weights = weightReg\n",
    "        self.a = QuantumRegister(1)\n",
    "        self.qc.add_register(self.a)\n",
    "\n",
    "    def MSELossFunction(self,outputReg,out):\n",
    "        self.qc.x(out)\n",
    "        self.qc.ccx(out,outputReg,self.a[0])\n",
    "        self.qc.x(out)\n",
    "        self.qc.x(outputReg)\n",
    "        self.qc.ccx(out,outputReg,self.a[0])\n",
    "        self.qc.z(self.a[0])\n",
    "        self.qc.x(outputReg)\n",
    "        return self.a[0]\n",
    "    \n",
    "    def qDD(self,error,learnRate,kineticTerm):\n",
    "        for w in self.weights:\n",
    "            self.qc.cu1(learnRate,error,w)\n",
    "        QFTransform(self.qc,self.weights,swap=False)\n",
    "        for w in self.weights:\n",
    "            self.qc.u1(kineticTerm,w)\n",
    "        iQFTransform(self.qc,self.weights,swap=False)\n",
    "        \n",
    "\n",
    "    def train(self,outputReg,epochs,learnRate,kineticTerm):\n",
    "        lr = learnRate\n",
    "        kt = kineticTerm\n",
    "        self.resetAncillas()\n",
    "        for e in range(epochs):\n",
    "            #routine for cleaning the ancilla registers of all perceptrons before initiate another epoch\n",
    "            \n",
    "            for p in self.perceptrons:\n",
    "                out=p.feedForward()\n",
    "            error = self.MSELossFunction(outputReg,out)\n",
    "            self.qDD(error,lr,kt)\n",
    "            self.qc.reset(self.a)\n",
    "            self.resetAncillas()\n",
    "            #update of learnRate and kineticTerm \n",
    "            lr = lr*2\n",
    "            kt = kt/2\n",
    "\n",
    "    def test(self,outputReg,cr):\n",
    "        for p in self.perceptrons:\n",
    "            out = p.feedForward()\n",
    "        \n",
    "        i=0\n",
    "        for p in self.perceptrons[0].inputReg:\n",
    "            self.qc.measure(p,cr[i])\n",
    "            i+=1\n",
    "        self.qc.measure(outputReg,cr[i])\n",
    "        i+=1\n",
    "        self.qc.measure(out,cr[i])\n",
    "\n",
    "    def resetAncillas(self):\n",
    "        for p in self.perceptrons:\n",
    "            self.qc.reset(p.ancillaReg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xorNN = deepNN(qc,weightReg,[percep1,percep2,percep3])\n",
    "#outputReg[0] , epochs , learnRate=0.1 , kineticTerm = 10 \n",
    "epochs = 1\n",
    "learnRate = 0.1\n",
    "kineticTerm = 10\n",
    "\n",
    "xorNN.train(outputReg[0],epochs,learnRate,kineticTerm)\n",
    "\n",
    "newInput = QuantumRegister(2)\n",
    "newOutput = QuantumRegister(1)\n",
    "cr = ClassicalRegister(16)\n",
    "qc.add_register(newInput,newOutput,cr)\n",
    "\n",
    "testDatai = [(0,0),(0,1),(1,0),(1,1)]\n",
    "testDatao = [0,1,1,0]\n",
    "\n",
    "\n",
    "j=0\n",
    "for i in range(1):\n",
    "    if testDatai[i][0] == 1:\n",
    "        qc.x(newInput[0])\n",
    "    if testDatai[i][1] == 1:\n",
    "        qc.x(newInput[1])\n",
    "    if testDatao[i] == 1:\n",
    "        qc.x(newOutput[0])\n",
    "    \n",
    "    percep1.setInputReg(newInput)\n",
    "\n",
    "    xorNN.test(newOutput[0],[cr[j],cr[j+1],cr[j+2],cr[j+3]])\n",
    "    j+=4\n",
    "    xorNN.resetAncillas()\n",
    "    qc.reset(newInput)\n",
    "    qc.reset(newOutput)\n",
    "\n",
    "execute_locally(qc,draw_circuit=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
